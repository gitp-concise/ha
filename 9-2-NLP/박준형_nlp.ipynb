{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **9. NLP 세션 과제**\n",
    "\n",
    "- 이번 과제는 BPE 토크나이저를 직접 구현해보고, 훈련시켜보는 것입니다.\n",
    "\n",
    "- **각 셀의 실행 결과물을 같이** 저장해서, 드라이브에 업로드 된 과제 명세에 적혀있는 제출 방식을 참고하여 본 노트북 파일을 제출해주세요. </br></br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### **주의사항!**\n",
    "\n",
    "- BPE를 구현하는 코드는 조금만 검색해도 쉽게 찾을 수 있습니다. (유명하니까요...) 하지만 해당 코드를 먼저 찾아보는 것은 추천하지 않습니다.\n",
    "\n",
    "- 본 과제의 목적은 구현 능력을 기르는 데 있습니다. 이론을 실제 코드로 구현하는 능력이 있고, 없고는 굉장히 큰 차이입니다!!\n",
    "\n",
    "- 따라서, 본 과제를 수행할 때, **BPE의 이론을 먼저\n",
    "충분히 복습**하고, **다른 샘플 코드를 보지 않고** 각각의 기능을 어떻게 구현할지 충분히 고민해보시기 바랍니다!\n",
    "\n",
    "- 인터넷에 샘플 코드가 많다는 건 여러분들도 충분히 하실 수 있다는 의미니까요!!!"
   ],
   "metadata": {
    "id": "EQx1Dj7XbS-i"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. BPE Tokenizer 구현하기 (70점, 각 세부 파트별 부분점수 있음)\n",
    "\n",
    "  **BPE Tokenizer**를 구현하기 위해서, 크게 다음 **세가지** 부분으로 쪼갤 수 있습니다.\n",
    "\n",
    "```\n",
    "  1) 전체 corpus를 공백으로 분리하고, {단어:빈도수} 형태의 vocabulary 사전을 구성하는 부분\n",
    "\n",
    "  2) 구성된 vocabulary 사전을 순회하면서, 사전 내 character 토큰 및 각각의 등장 횟수를 반환해 주는 부분\n",
    "\n",
    "  3) text에서 가장 자주 등장한 pair을 연결해주는 부분\n",
    "```\n",
    "\n",
    "본 과제에서 하실 일은 각각의 함수 코드를 직접 작성해보고, 각각의 함수를 모두 합쳐 최종적으로 BPE Tokenizer를 구현하는 것입니다!\n",
    "\n",
    "**Hint**: Collections 패키지의 defaultdict 클래스의 활용법을 찾아보시면 좀 더 손쉽게 구현할 수 있습니다."
   ],
   "metadata": {
    "id": "wUAzagMqbZad"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from collections import defaultdict"
   ],
   "metadata": {
    "id": "P8viuw3utO0f",
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:22.365893Z",
     "start_time": "2024-08-09T10:29:22.361266Z"
    }
   },
   "execution_count": 213,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "여러분이 작성한 코드가 맞는지 스스로 감을 잡으실 수 있도록, 각 함수 별로 샘플 corpus를 함수에 넣었을 때 나와야 하는 결과를 함께 제시하도록 하겠습니다. 샘플 corpus는 다음과 같습니다."
   ],
   "metadata": {
    "id": "FzvipA3QqYth"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sample_corpus = ['YBAGTA YBECTA YBIGTA YBOGTA YBUGTA',\n",
    "                 'I love YBIGTA',\n",
    "                 'I like YBIGTA',\n",
    "                 'what is YBAGTA']"
   ],
   "metadata": {
    "id": "fAVFREwObZAR",
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:22.391451Z",
     "start_time": "2024-08-09T10:29:22.388405Z"
    }
   },
   "execution_count": 214,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) 사전만들기 함수 (20점)\n",
    "\n",
    " 첫번째 함수는 corpus가 입력으로 주어졌을 때, 이에 기반하여 Vocabulary 사전을 구축하는 함수입니다. 이때, input/output 형태는 다음과 같습니다.\n",
    "\n",
    "\n",
    "  - `input` : 여러 개의 문자열로 이루어진 리스트 (sample corpus와 형태 동일)\n",
    "  - `output` : 여러 개의 단어:빈도수 쌍으로 이루어진 딕셔너리 (예시: `{단어1:빈도수1, 단어2:빈도수2, ... }` )\n",
    "\n",
    "\n",
    "\n",
    "**TODO**:\n",
    "  input 리스트 안의 문자열들에 대해서, 공백을 기준으로 분리한 각각의 단어와 그 빈도수를 딕셔너리 형태로 리턴하는 함수를 정의하세요.\n",
    "\n",
    " 이때, 추후 두번째, 세번째 함수 기능 구현의 편의성을 위해, output 딕셔너리 내 단어 형식을 다음과 같이 맞춰주세요,\n",
    "- 예시: `'Y B I G T A </w>'` -> 글자 사이 공백 추가, 마지막에 postfix 토큰  `</w>` 추가"
   ],
   "metadata": {
    "id": "kJaDz00rq8y5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def 사전만들기(corpus):\n",
    "    ##### TODO #####\n",
    "    # 함수 안을 채워주세요 #\n",
    "    # 이미 작성된 코드는 지우시면 안됩니다! #\n",
    "    # list(map(lambda s: s.split(), corpus))\n",
    "    strList: list[str] = sum(list(map(lambda s: s.split(), corpus)), [])\n",
    "    strList = list(map(lambda s: \" \".join(s) + \" </w>\", strList))\n",
    "    vocab = defaultdict(int)\n",
    "    for s in strList:\n",
    "        vocab[s] += 1\n",
    "    return dict(vocab)"
   ],
   "metadata": {
    "id": "UxI-cMFMst4H",
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:22.400979Z",
     "start_time": "2024-08-09T10:29:22.395218Z"
    }
   },
   "execution_count": 215,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "위에서 정의한 `사전만들기` 함수를 sample_corpus에 적용시 다음과 같은 결과가 리턴되어야 합니다.\n",
    "\n",
    "\n",
    "- 입력:\n",
    "```\n",
    "vocab = 사전만들기(sample_corpus)\n",
    "vocab\n",
    "```\n",
    "\n",
    "- 결과:\n",
    "```\n",
    "{'Y B A G T A </w>': 2,\n",
    " 'Y B E C T A </w>': 1,\n",
    " 'Y B I G T A </w>': 3,\n",
    " 'Y B O G T A </w>': 1,\n",
    " 'Y B U G T A </w>': 1,\n",
    " 'I </w>': 2,\n",
    " 'l o v e </w>': 1,\n",
    " 'l i k e </w>': 1,\n",
    " 'w h a t </w>': 1,\n",
    " 'i s </w>': 1}\n",
    " ```"
   ],
   "metadata": {
    "id": "IvpUlmehueuZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 다음 코드를 실행한 결과값을 위의 결과와 비교해서 함수를 잘 작성했는지 확인해보세요!\n",
    "vocab = 사전만들기(sample_corpus)\n",
    "vocab"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UFF9e-zAtCpk",
    "outputId": "862d5287-d978-4062-945a-e7e519965112",
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:22.407318Z",
     "start_time": "2024-08-09T10:29:22.403166Z"
    }
   },
   "execution_count": 216,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Y B A G T A </w>': 2,\n 'Y B E C T A </w>': 1,\n 'Y B I G T A </w>': 3,\n 'Y B O G T A </w>': 1,\n 'Y B U G T A </w>': 1,\n 'I </w>': 2,\n 'l o v e </w>': 1,\n 'l i k e </w>': 1,\n 'w h a t </w>': 1,\n 'i s </w>': 1}"
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) 토큰등장횟수 함수 (20점)\n",
    "\n",
    "다음으로는, `사전만들기`함수로 얻은 vocab 딕셔너리를 입력을 받아서, 사전에 포함된 글자 각각의 등장 횟수를 반환해주는 함수를 구현해 봅시다.\n",
    "\n",
    "인풋, 아웃풋 형태는 다음과 같습니다.\n",
    "\n",
    "- `input` : `사전만들기`함수의 output\n",
    "- `output`: {글자:빈도수} 구조의 tokens 딕셔너리,\n",
    "    예) {'Y':4, 'B':8, .... }"
   ],
   "metadata": {
    "id": "BnTUlA3ywksi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def 토큰등장횟수(vocab):\n",
    "    ##### TODO #####\n",
    "    # 함수 안을 채워주세요 #\n",
    "    # 이미 작성된 코드는 지우시면 안됩니다! #\n",
    "    result = defaultdict(int)\n",
    "    for key, val in vocab.items():\n",
    "        charList: list[str] = key.split()\n",
    "        for c in charList:\n",
    "            result[c] += val\n",
    "\n",
    "    return dict(result)"
   ],
   "metadata": {
    "id": "sB1gtxnBtGyA",
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:22.412984Z",
     "start_time": "2024-08-09T10:29:22.409443Z"
    }
   },
   "execution_count": 217,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "첫번째로 정의한 `사전만들기`함수에서 반환된 vocab을 `토큰등장횟수`에 넣었을때 반환되는 결과는 다음과 같아야 합니다.\n",
    "\n",
    "```\n",
    "{'Y': 8,\n",
    " 'B': 8,\n",
    " 'A': 10,\n",
    " 'G': 7,\n",
    " 'T': 8,\n",
    " '</w>': 14,\n",
    " 'E': 1,\n",
    " 'C': 1,\n",
    " 'I': 5,\n",
    " 'O': 1,\n",
    " 'U': 1,\n",
    " 'l': 2,\n",
    " 'o': 1,\n",
    " 'v': 1,\n",
    " 'e': 2,\n",
    " 'i': 2,\n",
    " 'k': 1,\n",
    " 'w': 1,\n",
    " 'h': 1,\n",
    " 'a': 1,\n",
    " 't': 1,\n",
    " 's': 1}\n",
    " ```\n",
    "\n",
    " 위와 같은 결과가 나오는지, 다음 셀을 실행하여 확인해볼 수 있습니다."
   ],
   "metadata": {
    "id": "-gYNuT91mAwb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 다음 코드를 실행한 결과값을 위의 결과와 비교해서 함수를 잘 작성했는지 확인해보세요!\n",
    "result = 토큰등장횟수(vocab)\n",
    "result"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qalAYLn4z9to",
    "outputId": "d5dbcac2-1d6c-4cee-b59c-0a780c22d8c1",
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:22.415994Z",
     "start_time": "2024-08-09T10:29:22.413651Z"
    }
   },
   "execution_count": 218,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Y': 8,\n 'B': 8,\n 'A': 10,\n 'G': 7,\n 'T': 8,\n '</w>': 14,\n 'E': 1,\n 'C': 1,\n 'I': 5,\n 'O': 1,\n 'U': 1,\n 'l': 2,\n 'o': 1,\n 'v': 1,\n 'e': 2,\n 'i': 2,\n 'k': 1,\n 'w': 1,\n 'h': 1,\n 'a': 1,\n 't': 1,\n 's': 1}"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3) 페어합치기 함수 (30점)\n",
    "\n",
    "마지막 함수입니다. 마지막으로, corpus에서 가장 자주 등장한 페어를 엮어 새롭게 vocab에 추가하는 기능을 구현해봅시다.\n",
    "\n",
    "이를 구현하기 위해서, 다시 다음 두 단계로 쪼갤 수 있습니다.\n",
    "\n",
    "1) `페어등장횟수` (15점): 각 페어가 등장한 횟수를 세어 딕셔너리 형태로 반환\n",
    "- `input` : vocab\n",
    "- `output`: {(글자1,글자2):등장횟수, (글자2,글자3):등장횟수,...} 형식의 딕셔너리\n",
    " -> 아래 샘플 결과 형태를 확인하세요.\n",
    "\n",
    "\n",
    "2) `페어합치기` (15점):\n",
    "-   `input`: vocab, 가장 자주 등장한 Tuple 형태의 pair\n",
    "- `output`: 새롭게 업데이트한 tokens 사전\n",
    "\n",
    "\n",
    "먼저, `페어등장횟수`함수부터 구현해 봅시다.\n"
   ],
   "metadata": {
    "id": "5O9lm0cK0wn2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def 페어등장횟수(vocab):\n",
    "    ##### TODO #####\n",
    "    # 함수 안을 채워주세요 #\n",
    "    # 이미 작성된 코드는 지우시면 안됩니다! #\n",
    "    def splitToPair(s: str) -> list[tuple[str]]:\n",
    "        charList: list[str] = s.split()\n",
    "        if len(charList) < 2:\n",
    "            return []\n",
    "        pairList = []\n",
    "        for i in range(0, len(charList) - 1):\n",
    "            pairList.append(tuple(charList[i:i + 2]))\n",
    "        return pairList\n",
    "\n",
    "    pairs = defaultdict(int)\n",
    "    for key, items in vocab.items():\n",
    "        for pair in splitToPair(key):\n",
    "            pairs[pair] += items\n",
    "    return dict(pairs)"
   ],
   "metadata": {
    "id": "1XCrMW9U0BdX",
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:22.418711Z",
     "start_time": "2024-08-09T10:29:22.416534Z"
    }
   },
   "execution_count": 219,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "위 함수에 우리의 예시를 넣어보면 다음과 같은 결과가 나와야 합니다.\n",
    "\n",
    "```\n",
    "{('Y', 'B'): 8,\n",
    " ('B', 'A'): 2,\n",
    " ('A', 'G'): 2,\n",
    " ('G', 'T'): 7,\n",
    " ('T', 'A'): 8,\n",
    " ('A', '</w>'): 8,\n",
    " ('B', 'E'): 1,\n",
    " ('E', 'C'): 1,\n",
    " ('C', 'T'): 1,\n",
    " ('B', 'I'): 3,\n",
    " ('I', 'G'): 3,\n",
    " ('B', 'O'): 1,\n",
    " ('O', 'G'): 1,\n",
    " ('B', 'U'): 1,\n",
    " ('U', 'G'): 1,\n",
    " ('I', '</w>'): 2,\n",
    " ('l', 'o'): 1,\n",
    " ('o', 'v'): 1,\n",
    " ('v', 'e'): 1,\n",
    " ('e', '</w>'): 2,\n",
    " ('l', 'i'): 1,\n",
    " ('i', 'k'): 1,\n",
    " ('k', 'e'): 1,\n",
    " ('w', 'h'): 1,\n",
    " ('h', 'a'): 1,\n",
    " ('a', 't'): 1,\n",
    " ('t', '</w>'): 1,\n",
    " ('i', 's'): 1,\n",
    " ('s', '</w>'): 1}\n",
    " ```\n",
    "\n",
    " 위와 같이, 튜플로 묶인 두 개의 토큰 페어와, 각 페어별 등장횟수로 이루어진 딕셔너리가 반환되어야 합니다. 아래 코드를 실행해 결과값이 같은지 확인해보세요."
   ],
   "metadata": {
    "id": "uVtbBVjarbJv"
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{('Y', 'B'): 8,\n ('B', 'A'): 2,\n ('A', 'G'): 2,\n ('G', 'T'): 7,\n ('T', 'A'): 8,\n ('A', '</w>'): 8,\n ('B', 'E'): 1,\n ('E', 'C'): 1,\n ('C', 'T'): 1,\n ('B', 'I'): 3,\n ('I', 'G'): 3,\n ('B', 'O'): 1,\n ('O', 'G'): 1,\n ('B', 'U'): 1,\n ('U', 'G'): 1,\n ('I', '</w>'): 2,\n ('l', 'o'): 1,\n ('o', 'v'): 1,\n ('v', 'e'): 1,\n ('e', '</w>'): 2,\n ('l', 'i'): 1,\n ('i', 'k'): 1,\n ('k', 'e'): 1,\n ('w', 'h'): 1,\n ('h', 'a'): 1,\n ('a', 't'): 1,\n ('t', '</w>'): 1,\n ('i', 's'): 1,\n ('s', '</w>'): 1}"
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다음 코드를 실행한 결과값을 위의 결과와 비교해서 함수를 잘 작성했는지 확인해보세요!\n",
    "pairs = 페어등장횟수(vocab)\n",
    "pairs"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W49OoJPX1NGv",
    "outputId": "8343186c-ff7f-4c17-b110-2c708c061270",
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:22.421598Z",
     "start_time": "2024-08-09T10:29:22.419287Z"
    }
   },
   "execution_count": 220
  },
  {
   "cell_type": "markdown",
   "source": [
    "다음으로, `페어합치기` 함수를 구현해봅시다. `페어합치기` 함수는 `페어등장횟수` 함수로 계산된 페어 빈도수를 바탕으로, BPE 로직에 맞게 vocab을 업데이트합니다."
   ],
   "metadata": {
    "id": "S8Qg5KZzr78E"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def 페어합치기(pairs, vocab):\n",
    "    ##### TODO #####\n",
    "    # 함수 안을 채워주세요 #\n",
    "    # 이미 작성된 코드는 지우시면 안됩니다! #\n",
    "    # 가장 빈도수 높은 쌍 가져오기\n",
    "    pair: tuple[str] = max(pairs, key=pairs.get)\n",
    "\n",
    "    new_vocab = dict()\n",
    "    vocab_list = list(vocab.keys())\n",
    "    for s in vocab_list:\n",
    "        s_split = s.split()\n",
    "        replace_idx = []\n",
    "        for i in range(0, len(s_split) - 1):\n",
    "            if s_split[i] == pair[0] and s_split[i + 1] == pair[1]:\n",
    "                replace_idx += [i]\n",
    "        new_s = s_split\n",
    "        for idx in replace_idx:\n",
    "            new_s[idx] = \"\".join(pair)\n",
    "            del new_s[idx + 1]\n",
    "        new_vocab[\" \".join(new_s)] = vocab[s]\n",
    "\n",
    "    return new_vocab\n"
   ],
   "metadata": {
    "id": "NHRf7TB41Rj3",
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:22.424556Z",
     "start_time": "2024-08-09T10:29:22.422114Z"
    }
   },
   "execution_count": 221,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "작성한 `페어합치기` 함수에 우리의 예시를 넣으면 다음과 같은 결과를 반환합니다.\n",
    "\n",
    "```\n",
    "{'YB A G T A </w>': 2,\n",
    " 'YB E C T A </w>': 1,\n",
    " 'YB I G T A </w>': 3,\n",
    " 'YB O G T A </w>': 1,\n",
    " 'YB U G T A </w>': 1,\n",
    " 'I </w>': 2,\n",
    " 'l o v e </w>': 1,\n",
    " 'l i k e </w>': 1,\n",
    " 'w h a t </w>': 1,\n",
    " 'i s </w>': 1}\n",
    " ```\n",
    "\n",
    " 아래 코드를 실행해 결과값이 같은지 확인해보세요."
   ],
   "metadata": {
    "id": "1C6d--MZtaPM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 다음 코드를 실행한 결과값을 위의 결과와 비교해서 함수를 잘 작성했는지 확인해보세요!\n",
    "vocab = 페어합치기(pairs, vocab)\n",
    "vocab"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BETYArqds9P8",
    "outputId": "21365658-190a-4602-949e-b98e569ce4bb",
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:22.429509Z",
     "start_time": "2024-08-09T10:29:22.427514Z"
    }
   },
   "execution_count": 223,
   "outputs": [
    {
     "data": {
      "text/plain": "{'YB A G T A </w>': 2,\n 'YB E C T A </w>': 1,\n 'YB I G T A </w>': 3,\n 'YB O G T A </w>': 1,\n 'YB U G T A </w>': 1,\n 'I </w>': 2,\n 'l o v e </w>': 1,\n 'l i k e </w>': 1,\n 'w h a t </w>': 1,\n 'i s </w>': 1}"
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. BPE Tokenizer Train (30점)\n",
    "\n",
    "이제 BPE 트레이닝을 위한 각 파트 구현을 완료했습니다! **각각의 함수를 합쳐서 BPE Tokenizer의 학습을 수행하는 `학습` 함수를 작성해주세요. (15점)**\n",
    "\n",
    " - 1번 파트에서 작성한 함수들은 한번 vocab을 업데이트하는 데 필요한 함수들입니다.\n",
    " - `n_iter`인자(int type)를 받아, 입력받은 횟수만큼 vocab을 업데이트하도록 함수를 작성해주세요.\n",
    "\n",
    "1번 파트에서 모든 함수를 잘 작성했다면, 트레이닝 함수는 간단히 작성하실 수 있습니다."
   ],
   "metadata": {
    "id": "G_oFDna61v2A"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def 학습(corpus, n_iter):\n",
    "    ##### TODO #####\n",
    "    # 함수 안을 채워주세요 #\n",
    "    # 이미 작성된 코드는 지우시면 안됩니다! #\n",
    "    vocab = 사전만들기(corpus)\n",
    "    for i in range(n_iter):\n",
    "        tokens = 토큰등장횟수(vocab)\n",
    "        pairs = 페어등장횟수(vocab)\n",
    "        new_vocab = 페어합치기(pairs, vocab)\n",
    "        vocab = new_vocab\n",
    "\n",
    "    tokens = 토큰등장횟수(vocab)\n",
    "    return tokens"
   ],
   "metadata": {
    "id": "OIdnzNDDoP1j",
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:22.432264Z",
     "start_time": "2024-08-09T10:29:22.430089Z"
    }
   },
   "execution_count": 224,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "학습 함수에 sample corpus를 넣고, `n_iter`을 10으로 정한 후 시행한 결과는 다음과 같습니다.\n",
    "\n",
    "```\n",
    "{'YBAGTA</w>': 2,\n",
    " 'YB': 3,\n",
    " 'E': 1,\n",
    " 'C': 1,\n",
    " 'TA</w>': 1,\n",
    " 'YBIGTA</w>': 3,\n",
    " 'O': 1,\n",
    " 'GTA</w>': 2,\n",
    " 'U': 1,\n",
    " 'I</w>': 2,\n",
    " 'l': 2,\n",
    " 'o': 1,\n",
    " 'v': 1,\n",
    " 'e</w>': 2,\n",
    " 'i': 2,\n",
    " 'k': 1,\n",
    " 'w': 1,\n",
    " 'h': 1,\n",
    " 'a': 1,\n",
    " 't': 1,\n",
    " '</w>': 2,\n",
    " 's': 1}\n",
    " ```\n"
   ],
   "metadata": {
    "id": "i7-6x84hxhpM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokens = 학습(sample_corpus, n_iter=10)\n",
    "tokens"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jk1iZqkJv1YU",
    "outputId": "725ca289-d10a-4388-bbc4-3208d8363438",
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:22.435223Z",
     "start_time": "2024-08-09T10:29:22.432774Z"
    }
   },
   "execution_count": 225,
   "outputs": [
    {
     "data": {
      "text/plain": "{'YBAGTA</w>': 2,\n 'YB': 3,\n 'E': 1,\n 'C': 1,\n 'TA</w>': 1,\n 'YBIGTA</w>': 3,\n 'O': 1,\n 'GTA</w>': 2,\n 'U': 1,\n 'I</w>': 2,\n 'l': 2,\n 'o': 1,\n 'v': 1,\n 'e</w>': 2,\n 'i': 2,\n 'k': 1,\n 'w': 1,\n 'h': 1,\n 'a': 1,\n 't': 1,\n '</w>': 2,\n 's': 1}"
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**또, 직접 학습을 시켜봅시다. (15점)**\n",
    "\n",
    "\n",
    "학습용 corpus는 각자 자유롭게 정해주세요. (ex. 노래 가사 등등...)\n",
    "\n",
    "- 단, 빈도수 기반의 BPE 토크나이저의 효과적인 학습을 위해서, 학습 corpus는 다음 조건을 만족하면 더 좋겠죠?\n",
    "\n",
    "  - 같은 단어가 여러개 들어가있고 적당히 긴 텍스트"
   ],
   "metadata": {
    "id": "7hQsGGeet65Q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "##### TODO #####\n",
    "# 리스트 안에 train corpus를 자유롭게 채워주세요 #\n",
    "\n",
    "train_corpus = [\n",
    "    \"The beautiful sun rises over the calm ocean, bringing light to the sleeping world.\",\n",
    "    \"As the sun sets behind the mountains, the sky turns into a canvas of colors.\",\n",
    "    \"The sun shines brightly, reflecting off the waves of the vast ocean.\",\n",
    "    \"In the early morning, the sun slowly rises, painting the sky with warm hues.\",\n",
    "    \"The calm ocean mirrors the setting sun, creating a perfect reflection of the sky.\",\n",
    "    \"When the sun rises, it lights up the entire horizon with its golden rays.\",\n",
    "    \"The sun and the moon dance across the sky, sharing the endless horizon.\"\n",
    "                ]"
   ],
   "metadata": {
    "id": "O1cnQyJs1mVm",
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:22.437642Z",
     "start_time": "2024-08-09T10:29:22.435809Z"
    }
   },
   "execution_count": 226,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "##### TODO #####\n",
    "# 여러분의 train_corpus를 구현한 BPE 토크나이저 학습 함수에 넣고, 결과값을 프린트하세요\n",
    "학습(train_corpus, n_iter=10)"
   ],
   "metadata": {
    "id": "bnJ9ynBfx5Nl",
    "ExecuteTime": {
     "end_time": "2024-08-09T10:29:22.441997Z",
     "start_time": "2024-08-09T10:29:22.438173Z"
    }
   },
   "execution_count": 227,
   "outputs": [
    {
     "data": {
      "text/plain": "{'T': 4,\n 'he</w>': 4,\n 'b': 4,\n 'e': 29,\n 'a': 22,\n 'u': 6,\n 't': 22,\n 'i': 18,\n 'f': 9,\n 'l': 16,\n '</w>': 33,\n 'su': 7,\n 'n</w>': 13,\n 'r': 25,\n 's': 22,\n 's</w>': 12,\n 'o': 26,\n 'v': 4,\n 'the</w>': 17,\n 'c': 13,\n 'm': 7,\n 'n': 12,\n ',</w>': 8,\n 'ing': 7,\n 'in': 7,\n 'g': 4,\n 'h': 12,\n 'p': 4,\n 'w': 6,\n 'd': 6,\n '.</w>': 7,\n 'A': 1,\n 'k': 4,\n 'y': 8,\n 'I': 1,\n 'W': 1,\n 'e</w>': 2,\n 'z': 2}"
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 보너스 질문 ( 추가점수 10점 )\n",
    "BPE 방식의 한계점은 무엇이고, 이러한 한계점이 왜 나타나는지 고민해보고 그 이유를 자유롭게 설명해주세요."
   ],
   "metadata": {
    "id": "t-d6MqpC5i8o"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "BPE는 학습데이터 내에서 자주 등장하는 단어를 학습해서 사전을 구축합니다.  그러나 새로운 데이터에서 훈련되지 않은 단어나 드물게 등장하는 단어가 나타나면, 이를 처리하는 데 한계가 생깁니다.즉 새로운 데이터에서 신조어, 전뭉용어들이 나오면 제대로 처리를 못 할 수 있습니다.\n"
   ],
   "metadata": {
    "id": "-axLI1jC6EcS"
   }
  }
 ]
}
